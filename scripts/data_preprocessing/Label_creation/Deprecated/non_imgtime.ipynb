{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'eid' column from the baseline imputed CSV and convert it to a NumPy array\n",
    "inceid = pd.read_csv('../../../results/Process_missingness/baseline_imputed.csv')['eid'].to_numpy()\n",
    "\n",
    "# Create a mapping from ALT_CODE to PheCode using the phecode_icd10.csv file\n",
    "icdmap = dict(zip(\n",
    "    pd.read_csv('../../../data/phecode_icd10.csv')['ALT_CODE'].to_numpy(),\n",
    "    pd.read_csv('../../../data/phecode_icd10.csv')['PheCode'].to_numpy()\n",
    "))\n",
    "\n",
    "# Load PheCodes from phecode.csv and concatenate them into a single NumPy array\n",
    "phe = np.concatenate(pd.read_csv('../../../data/phecode.csv').to_numpy())\n",
    "\n",
    "# Initialize a dictionary to store valid ICD to PheCode mappings\n",
    "valid = {}\n",
    "for k, v in icdmap.items():\n",
    "    if v in phe:\n",
    "        valid[k] = v\n",
    "\n",
    "# Initialize a dictionary to store valid ICD to PheCode mappings where keys end with 'X'\n",
    "validX = {}\n",
    "for k, v in icdmap.items():\n",
    "    if k.endswith('X') and v in phe:\n",
    "        validX[k[:-1]] = v  # Remove the trailing 'X' from the key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icdtophe(icd):\n",
    "    \"\"\"\n",
    "    Maps an ICD code to its corresponding PheCode.\n",
    "\n",
    "    Parameters:\n",
    "        icd (str): The ICD code to be mapped.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - bool: Indicates whether a valid PheCode was found.\n",
    "            - str or None: The corresponding PheCode if found, else None.\n",
    "    \"\"\"\n",
    "    # Check if the full ICD code exists in the valid mapping\n",
    "    if icd in valid:\n",
    "        return True, valid[icd]\n",
    "    \n",
    "    # Check if the ICD code without the last three characters exists in the validX mapping\n",
    "    elif icd[:-3] in validX:\n",
    "        return True, validX[icd[:-3]]\n",
    "    \n",
    "    # If neither condition is met, return False and None\n",
    "    else:\n",
    "        return False, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd3=pd.read_csv('../../../data/cd3.tsv',delimiter='\\t')\n",
    "icdmapnonalt=dict(zip(pd.read_csv('../../../data/phecode_icd10.csv')['ICD10'].to_numpy(),pd.read_csv('../../../data/phecode_icd10.csv')['PheCode'].to_numpy()))\n",
    "phemeaning=dict(zip(pd.read_csv('../../../data/phecode_definitions1.2.csv')['phecode'].to_numpy(),pd.read_csv('../../../data/phecode_definitions1.2.csv')['phenotype'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_intv(intv):\n",
    "    \"\"\"\n",
    "    Resolves an interval of ICD10 codes to their corresponding PheCodes.\n",
    "\n",
    "    Parameters:\n",
    "        intv (str): A string representing the ICD10 code interval in the format 'start-end'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of PheCodes that fall within the specified ICD10 interval.\n",
    "    \"\"\"\n",
    "    inc = []\n",
    "    try:\n",
    "        # Split the interval into start and end ICD10 codes\n",
    "        start, end = intv.split('-')\n",
    "    except ValueError:\n",
    "        print(f\"Invalid interval format: '{intv}'. Expected format 'start-end'.\")\n",
    "        return inc\n",
    "\n",
    "    # Iterate through the ICD10 to PheCode mapping to find codes within the interval\n",
    "    for k, v in icdmapnonalt.items():\n",
    "        if start <= k <= end:\n",
    "            inc.append(v)\n",
    "\n",
    "    # Handle specific case where no PheCodes are found and the interval starts with 'C07', your case may vary\n",
    "    if not inc:\n",
    "        if intv[:3] == 'C07':\n",
    "            # Attempt to map the first three characters of the start code\n",
    "            truncated_code = start[:3]\n",
    "            phe_code = icdmapnonalt.get(truncated_code)\n",
    "            if phe_code:\n",
    "                inc.append(phe_code)\n",
    "            else:\n",
    "                print(f\"No PheCode found for truncated code: '{truncated_code}'.\")\n",
    "\n",
    "    # If still no PheCodes are found, log the unresolved interval\n",
    "    if not inc:\n",
    "        print(f\"Unresolved interval: '{intv}'.\")\n",
    "\n",
    "    return inc\n",
    "\n",
    "def resolve_code(cd):\n",
    "    \"\"\"\n",
    "    Resolves a single ICD10 code to its corresponding PheCode.\n",
    "\n",
    "    Parameters:\n",
    "        cd (str): The ICD10 code to be resolved.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the corresponding PheCode if found, else [np.nan].\n",
    "    \"\"\"\n",
    "    phe = ''\n",
    "\n",
    "    # Direct mapping from ICD10 to PheCode using icdmapnonalt\n",
    "    if cd in icdmapnonalt:\n",
    "        phe = icdmapnonalt[cd]\n",
    "    \n",
    "    # Mapping based on the first three characters of the ICD10 code using icdmap\n",
    "    elif cd[:3] in icdmap:\n",
    "        phe = icdmap[cd[:3]]\n",
    "    \n",
    "    # Direct mapping from the first three characters of the ICD10 code using icdmapnonalt\n",
    "    elif cd[:3] in icdmapnonalt:\n",
    "        phe = icdmapnonalt[cd[:3]]\n",
    "    \n",
    "    else:\n",
    "        phe = np.nan\n",
    "        # Attempt to append '.0' if not present and try resolving again\n",
    "        if '.' not in cd:\n",
    "            cd_extended = cd + '.0'\n",
    "            phe = resolve_code(cd_extended)[0]\n",
    "        else:\n",
    "            # Log unresolved ICD10 codes, try to handle it manually\n",
    "            print(f\"Unresolved ICD10 code: {cd}\")\n",
    "    \n",
    "    return [phe]\n",
    "\n",
    "cdcancer = {}\n",
    "mDF = []\n",
    "\n",
    "for row in cd3.to_numpy():\n",
    "    # Extract the ICD10 code(s) from the third column of the row\n",
    "    icd_codes = row[2]\n",
    "    \n",
    "    # Determine the type of ICD10 entry and resolve accordingly\n",
    "    if '-' not in icd_codes:\n",
    "        # Single ICD10 code without a range\n",
    "        resolved = resolve_code(icd_codes)\n",
    "    elif ',' not in icd_codes:\n",
    "        # ICD10 code represents an interval (range)\n",
    "        resolved = resolve_intv(icd_codes)\n",
    "    else:\n",
    "        # ICD10 codes include multiple entries separated by commas\n",
    "        resolved = []\n",
    "        for itm in icd_codes.split(', '):\n",
    "            if '-' not in itm:\n",
    "                # Resolve individual ICD10 code\n",
    "                resolved += resolve_code(itm)\n",
    "            else:\n",
    "                # Resolve interval of ICD10 codes\n",
    "                resolved += resolve_intv(itm)\n",
    "    \n",
    "    # Remove duplicate PheCodes\n",
    "    unique_resolved = np.unique(resolved)\n",
    "    \n",
    "    # Filter PheCodes to include only those present in the 'phe' array\n",
    "    valid_phe_codes = [t for t in unique_resolved if t in phe]\n",
    "    \n",
    "    # Append each valid PheCode along with relevant information to 'mDF'\n",
    "    for phe_code in valid_phe_codes:\n",
    "        mDF.append([row[0], row[1], phe_code, phemeaning[phe_code]])\n",
    "    \n",
    "    # Assign the first valid PheCode to the 'cdcancer' dictionary for the given 'eid'\n",
    "    if valid_phe_codes:\n",
    "        cdcancer[row[0]] = valid_phe_codes[0]\n",
    "    else:\n",
    "        # Handle cases where no valid PheCode is found\n",
    "        cdcancer[row[0]] = np.nan\n",
    "        print(f\"No valid PheCode found for eid: {row[0]}\")\n",
    "mDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mDF).to_csv('../../../data/cancermap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include=['20001', '20002', '40001', '41270']\n",
    "includewtime=['40001,40007', '41270,41280', '20001,20007', '20002,20009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod6=pd.read_csv('../../../data/Self_report_FO_mappings_Jan2022.tsv',delimiter='\\t')\n",
    "cod6icd={}\n",
    "for i in cod6.to_numpy():\n",
    "    cod6icd[i[0]]=i[1]\n",
    "cod6icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_code(datai, data):\n",
    "    \"\"\"\n",
    "    Handles the resolution of codes based on the provided 'data' type.\n",
    "\n",
    "    Parameters:\n",
    "        datai (float or str): The input code identifier to be resolved.\n",
    "        data (str): A string indicating the type of data ('20001', '20002', or others).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - status (bool): Indicates whether the code was successfully resolved.\n",
    "            - code (str or None): The corresponding PheCode if resolved; otherwise, None.\n",
    "    \"\"\"\n",
    "    status = False  # Initialize the status as False by default\n",
    "    code = None     # Initialize code as None\n",
    "\n",
    "    # Handle the case when 'data' is '20002'\n",
    "    if data == '20002':\n",
    "        try:\n",
    "            key = int(float(datai))\n",
    "        except ValueError:\n",
    "            print(f\"Invalid datai value for data '20002': {datai}\")\n",
    "            return status, code\n",
    "\n",
    "        # Check if the converted key exists in the 'cod6icd' dictionary\n",
    "        if key in cod6icd:\n",
    "            # Retrieve the ICD code from 'cod6icd' and map it to a PheCode using 'icdtophe'\n",
    "            status, code = icdtophe(cod6icd[key])\n",
    "        else:\n",
    "            print(f\"Key {key} not found in 'cod6icd' for data '20002'.\")\n",
    "\n",
    "    # Handle the case when 'data' is '20001'\n",
    "    elif data == '20001':\n",
    "        try:\n",
    "            key = int(float(datai))\n",
    "        except ValueError:\n",
    "            print(f\"Invalid datai value for data '20001': {datai}\")\n",
    "            return status, code\n",
    "\n",
    "        # Check if the converted key exists in the 'cdcancer' dictionary\n",
    "        if key in cdcancer:\n",
    "            status = True          # Set status to True as the key exists\n",
    "            code = cdcancer[key]   # Retrieve the corresponding PheCode from 'cdcancer'\n",
    "        else:\n",
    "            print(f\"Key {key} not found in 'cdcancer' for data '20001'.\")\n",
    "\n",
    "    # Handle all other cases\n",
    "    else:\n",
    "        # Directly map 'datai' to a PheCode using 'icdtophe'\n",
    "        status, code = icdtophe(datai)\n",
    "\n",
    "    # Return the status and code based on whether the mapping was successful\n",
    "    if status:\n",
    "        return status, code\n",
    "    else:\n",
    "        return status, None\n",
    "\n",
    "handle_code(1002.0, '20001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Configure logging to capture warnings and errors\n",
    "logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Initialize the 'overall' dictionary to store results (assumed from previous context)\n",
    "overall = {}\n",
    "\n",
    "# Directory containing the CSV files\n",
    "ukb_csv_dir = '../../../results/cache/ukbcsv/'\n",
    "\n",
    "# Iterate over each 'data,time' pair in 'includewtime'\n",
    "for entry in includewtime:\n",
    "    # Split the entry into 'data_code' and 'time_code'\n",
    "    data_code, time_code = entry.split(',')\n",
    "    \n",
    "    # Initialize lists to store DataFrames for 'data_code' and 'time_code'\n",
    "    data_dfs = []\n",
    "    time_dfs = []\n",
    "    \n",
    "    # Iterate over sorted list of filenames in the 'ukbcsv' directory\n",
    "    for filename in sorted(os.listdir(ukb_csv_dir)):\n",
    "        file_path = os.path.join(ukb_csv_dir, filename)\n",
    "        \n",
    "        # Check if 'data_code' is present in the filename\n",
    "        if data_code in filename:\n",
    "            try:\n",
    "                # Read the CSV file without headers and append to 'data_dfs'\n",
    "                df = pd.read_csv(file_path, header=None)\n",
    "                data_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading file {file_path}: {e}\")\n",
    "        \n",
    "        # Check if 'time_code' is present in the filename\n",
    "        if time_code in filename:\n",
    "            try:\n",
    "                # Read the CSV file without headers and append to 'time_dfs'\n",
    "                df = pd.read_csv(file_path, header=None)\n",
    "                time_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error reading file {file_path}: {e}\")\n",
    "    \n",
    "    # Concatenate all DataFrames in 'data_dfs' along columns to form 'dataDF'\n",
    "    if data_dfs:\n",
    "        dataDF = pd.concat(data_dfs, axis=1)\n",
    "    else:\n",
    "        logging.warning(f\"No files found containing 'data_code': {data_code}\")\n",
    "        dataDF = pd.DataFrame()\n",
    "    \n",
    "    # Concatenate all DataFrames in 'time_dfs' along columns to form 'timeDF'\n",
    "    if time_dfs:\n",
    "        timeDF = pd.concat(time_dfs, axis=1)\n",
    "    else:\n",
    "        logging.warning(f\"No files found containing 'time_code': {time_code}\")\n",
    "        timeDF = pd.DataFrame()\n",
    "    \n",
    "    # Convert DataFrames to NumPy arrays for efficient processing\n",
    "    tnp = timeDF.to_numpy()\n",
    "    dnp = dataDF.to_numpy()\n",
    "    \n",
    "    # Initialize a list to store disease information per file\n",
    "    per_file_disease = []\n",
    "    \n",
    "    # Iterate over each row in the NumPy arrays\n",
    "    for row_index in range(tnp.shape[0]):\n",
    "        # Initialize a dictionary to store diseases and their earliest times for this row\n",
    "        disease_dict = {}\n",
    "        \n",
    "        # Iterate over each column in the current row\n",
    "        for col_index in range(tnp.shape[1]):\n",
    "            # Extract time and data values as strings\n",
    "            time_i = str(tnp[row_index, col_index])\n",
    "            data_i = str(dnp[row_index, col_index])\n",
    "            \n",
    "            # Proceed only if both time and data are not 'nan'\n",
    "            if time_i != 'nan' and data_i != 'nan':\n",
    "                # Call 'handle_code' function to resolve the data code\n",
    "                status, code = handle_code(data_i, data_code)\n",
    "                \n",
    "                # If the code was not successfully resolved, skip to next iteration\n",
    "                if not status:\n",
    "                    continue\n",
    "                \n",
    "                # Attempt to convert 'time_i' to float and check if it's negative\n",
    "                try:\n",
    "                    time_float = float(time_i)\n",
    "                    if time_float < 0:\n",
    "                        continue  # Skip if time is negative (indicating an error code)\n",
    "                except ValueError:\n",
    "                    # If 'time_i' cannot be converted to float (e.g., it's text from 41270), ignore\n",
    "                    pass\n",
    "                \n",
    "                # Update 'data_i' with the resolved code\n",
    "                data_i = code\n",
    "                \n",
    "                # If the disease code is already in 'disease_dict', keep the earliest time\n",
    "                if data_i in disease_dict:\n",
    "                    existing_time = disease_dict[data_i]\n",
    "                    # Formatted time, compare as strings\n",
    "                    if time_i < existing_time:\n",
    "                        disease_dict[data_i] = time_i\n",
    "                else:\n",
    "                    # Add the disease code and its time to 'disease_dict'\n",
    "                    disease_dict[data_i] = time_i\n",
    "        \n",
    "        # Append the 'disease_dict' dictionary to 'per_file_disease' list\n",
    "        per_file_disease.append(disease_dict)\n",
    "    \n",
    "    # Assign the 'per_file_disease' list to the 'overall' dictionary with 'data_code' as the key\n",
    "    overall[data_code] = per_file_disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pricare=pickle.load( open('../../../results/cache/pricare', 'rb'))\n",
    "fulleid=np.concatenate(pd.read_csv('../../../results/cache/ukbcsv/eid.csv',header=None).to_numpy())\n",
    "fulleid=list(fulleid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the processed results\n",
    "priprocessed = []\n",
    "\n",
    "# Iterate over each key in the 'fulleid' list\n",
    "for k in fulleid:\n",
    "    # Check if the current key 'k' is not present in the 'pricare' dictionary\n",
    "    if k not in pricare.keys():\n",
    "        # If 'k' is not in 'pricare', append an empty dictionary to 'priprocessed'\n",
    "        priprocessed.append({})\n",
    "    else:\n",
    "        # If 'k' exists in 'pricare', retrieve its associated value (a dictionary)\n",
    "        v = pricare[k]\n",
    "        # Initialize an empty dictionary to store processed data for this key\n",
    "        disedict = {}\n",
    "        \n",
    "        # Iterate over each key-value pair in the dictionary 'v'\n",
    "        for c, date in v.items():\n",
    "            status, code = handle_code(c, '42040')\n",
    "            # Proceed only if 'handle_code' returned a successful status\n",
    "            if status:\n",
    "                datai = code\n",
    "                if datai in disedict.keys():\n",
    "                    # If the current 'date' is earlier than the stored date, update it\n",
    "                    if date < disedict[datai]:\n",
    "                        disedict[datai] = date \n",
    "                else:\n",
    "                    disedict[datai] = date \n",
    "        # After processing all items, append the 'disedict' to 'priprocessed'\n",
    "        priprocessed.append(disedict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "focc=np.load('../../../results/cache/firstocc.npy',allow_pickle=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(focc.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the processed results for 'focc'\n",
    "foccprocessed = []\n",
    "\n",
    "# Iterate over each key in the 'fulleid' list\n",
    "for k in fulleid:\n",
    "    # Check if the current key 'k' is not present in the 'pricare' dictionary\n",
    "    if k not in pricare.keys():\n",
    "        # If 'k' is not in 'pricare', append an empty dictionary to 'foccprocessed'\n",
    "        foccprocessed.append({})\n",
    "    # If 'k' is present in 'pricare', check if its string representation is not in the 'focc' dictionary\n",
    "    elif str(k) not in focc.keys():\n",
    "        # If the string version of 'k' is not in 'focc', append an empty dictionary to 'foccprocessed'\n",
    "        foccprocessed.append({})\n",
    "    else:\n",
    "        # If 'str(k)' exists in 'focc', retrieve its associated value (a dictionary)\n",
    "        v = focc[str(k)]\n",
    "        # Initialize an empty dictionary to store processed data for this key\n",
    "        disedict = {}\n",
    "        \n",
    "        # Iterate over each key-value pair in the dictionary 'v'\n",
    "        for c, date in v.items():\n",
    "            # Call the 'handle_code' function with 'c' and a fixed string '130000'\n",
    "            # It returns a tuple: (status, code)\n",
    "            status, code = handle_code(c, '130000')\n",
    "            \n",
    "            # Proceed only if 'handle_code' returned a successful status\n",
    "            if status:\n",
    "                # Assign the returned 'code' to 'datai'\n",
    "                datai = code\n",
    "                \n",
    "                # Check if 'datai' already exists in 'disedict'\n",
    "                if datai in disedict.keys():\n",
    "                    # If the current 'date' is earlier than the stored date, update it\n",
    "                    if date < disedict[datai]:\n",
    "                        disedict[datai] = date \n",
    "                else:\n",
    "                    # If 'datai' is not in 'disedict', add it with the current 'date'\n",
    "                    disedict[datai] = date \n",
    "        \n",
    "        # After processing all items, append the 'disedict' to 'foccprocessed'\n",
    "        foccprocessed.append(disedict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall['42040']=priprocessed\n",
    "overall['130000']=foccprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in overall.items():\n",
    "    newv = []\n",
    "    for s in v:\n",
    "        # Initialize an empty dictionary to store valid key-time pairs\n",
    "        noerror = {}\n",
    "        for tempphe, time in s.items():\n",
    "            # Check if 'time' is one of the specified invalid dates\n",
    "            if time in ['1901-01-01', '1902-02-02', '1903-03-03', '2037-07-07']:\n",
    "                # If 'time' is invalid, skip this key-time pair\n",
    "                continue\n",
    "            else:\n",
    "                # If 'time' is valid, add the pair to 'noerror'\n",
    "                noerror[tempphe] = time\n",
    "        \n",
    "        # After processing all key-time pairs in 's', append 'noerror' to 'newv'\n",
    "        newv.append(noerror)\n",
    "    \n",
    "    # Update the 'overall' dictionary for key 'k' with the processed list 'newv'\n",
    "    overall[k] = newv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulleid_dict = {value: index for index, value in enumerate(fulleid)}\n",
    "incidx = [fulleid_dict[i] for i in inceid]\n",
    "incidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f34=np.concatenate(pd.read_csv('../../../results/cache/ukbcsv/34-0.0.csv',header=None).to_numpy())\n",
    "f52=np.concatenate(pd.read_csv('../../../results/cache/ukbcsv/52-0.0.csv',header=None).to_numpy())\n",
    "f53=np.concatenate(pd.read_csv('../../../results/cache/ukbcsv/53-0.0.csv',header=None).to_numpy())\n",
    "f53i=np.concatenate(pd.read_csv('../../../results/cache/ukbcsv/53-2.0.csv',header=None).to_numpy())\n",
    "eid=np.concatenate(pd.read_csv('../../../results/cache/ukbcsv/eid.csv',header=None).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgeid=pd.read_csv('../../../results/Preprocess/image_eid.csv')['x'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store calculated ages\n",
    "age_of_record = []\n",
    "age_till_now = []\n",
    "\n",
    "# Iterate over the 'f53' list with both index 'i' and element 'd'\n",
    "for i, d in enumerate(f53):\n",
    "    year = int(d.split('-')[0])\n",
    "    month = int(d.split('-')[1])\n",
    "    day = int(d.split('-')[2])\n",
    "    age_record = year - f34[i] + month / 12 - f52[i] / 12 + day / 365\n",
    "    age_of_record.append(age_record)\n",
    "    \n",
    "    age_now = 2024 - f34[i] - f52[i] / 12\n",
    "    age_till_now.append(age_now)\n",
    "\n",
    "# Display the 'age_till_now' list\n",
    "age_till_now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_of_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calctime(date, year, mo):\n",
    "    \"\"\"\n",
    "    Calculates the time difference between a given date and a reference year and month.\n",
    "\n",
    "    Parameters:\n",
    "        date (str): A date string in the format 'YYYY-MM-DD'.\n",
    "        year (int): The reference year to subtract from the date's year.\n",
    "        mo (int): The reference month to subtract from the date's month.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated time difference in years, including fractional years based on months and days.\n",
    "    \"\"\"\n",
    "    \n",
    "    y, m, d = np.array(date.split('-'), dtype=int)\n",
    "    time_diff = y - year + (m - mo) / 12 + d / 365\n",
    "    \n",
    "    return time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(overall['41270'])):\n",
    "    for k,v in overall['41270'][i].items():\n",
    "        overall['41270'][i][k]=calctime(v,f34[i],f52[i])\n",
    "for i in range(len(overall['42040'])):\n",
    "    for k,v in overall['42040'][i].items():\n",
    "        overall['42040'][i][k]=calctime(v,f34[i],f52[i])\n",
    "for i in range(len(overall['130000'])):\n",
    "    for k,v in overall['130000'][i].items():\n",
    "        overall['130000'][i][k]=calctime(v,f34[i],f52[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "count_dict = {}\n",
    "\n",
    "# Iterate over each key-value pair in the 'overall' dictionary\n",
    "for k, v in overall.items():\n",
    "    # Initialize an empty dictionary to count occurrences of sub-keys for the current main key\n",
    "    patient_dict = {}\n",
    "    \n",
    "    # Print the current main key and the number of entries it has\n",
    "    print(k, len(v))\n",
    "    \n",
    "    # Iterate over each dictionary in the list 'v'\n",
    "    for i in v:\n",
    "        # Iterate over each sub-key and its associated value in the inner dictionary 'i'\n",
    "        for s, t in i.items():\n",
    "            # If the sub-key 's' is already in 'patient_dict', increment its count\n",
    "            if s in patient_dict.keys():\n",
    "                patient_dict[s] += 1\n",
    "            else:\n",
    "                # If the sub-key 's' is not in 'patient_dict', initialize its count to 1\n",
    "                patient_dict[s] = 1\n",
    "    \n",
    "    # Assign the count dictionary 'patient_dict' to the main dictionary 'count_dict' under key 'k'\n",
    "    count_dict[k] = patient_dict\n",
    "\n",
    "# Assign the count dictionary to the variable 'data' for clarity\n",
    "data = count_dict\n",
    "\n",
    "# Define the output file path for the CSV\n",
    "output_file = '../../../results/imgsumdata.csv'\n",
    "\n",
    "# Open the output CSV file in write mode\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header row: 'Key' followed by sorted main keys from 'data'\n",
    "    writer.writerow(['Key'] + sorted(list(data.keys())))\n",
    "    \n",
    "    # Read the 'phecode.csv' file and extract inner keys\n",
    "    # Note: Assumes that 'phecode.csv' has a single column without a header\n",
    "    inner_keys = np.concatenate(pd.read_csv('../../../data/phecode.csv').to_numpy())\n",
    "    \n",
    "    # Iterate over each inner key to create rows for the CSV\n",
    "    for inner_key in inner_keys:\n",
    "        # Initialize the row with the current inner key as the first element\n",
    "        row = [str(inner_key)]\n",
    "        \n",
    "        # Iterate over each main key in 'data' to append counts or default values\n",
    "        for key in data.keys():\n",
    "            # Append the count if 'inner_key' exists in 'data[key]', else append an empty string\n",
    "            row.append(data[key].get(inner_key, ''))\n",
    "        \n",
    "        # Write the constructed row to the CSV file\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phe=list(phe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for i in range(502244):\n",
    "    \n",
    "    # Create a temporary array 'temp' filled with ones multiplied by the current age\n",
    "    temp = np.ones(len(phe)) * age_till_now[i]\n",
    "    for k, v in overall.items():\n",
    "        for code, time in v[i].items():\n",
    "            \n",
    "            # Find the index of the current 'code' in the 'phe' list\n",
    "            # This index corresponds to the position in the 'temp' array\n",
    "            dindex = phe.index(code)\n",
    "\n",
    "            time = float(time)\n",
    "            \n",
    "            # Check if the 'time' is greater than 'age_of_record'\n",
    "            if time - age_of_record[i] > 0:\n",
    "                if temp[dindex] > time:\n",
    "                    temp[dindex] = time\n",
    "            else:\n",
    "                temp[dindex] = np.nan\n",
    "    matrix.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix0_1 = []\n",
    "for i in matrix:\n",
    "    current_time = np.nanmax(i)\n",
    "    nan = np.where(np.isnan(i))[0]\n",
    "    diseases_sign = np.where(i != current_time)[0]\n",
    "    # Not being the current time indicates the disease has happened\n",
    "    temp = np.zeros(len(phe))\n",
    "    temp[diseases_sign] = 1\n",
    "    temp[nan] = np.nan\n",
    "    matrix0_1.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix0_1=np.array(matrix0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulleid_dict = {value: index for index, value in enumerate(fulleid)}\n",
    "incidx = [fulleid_dict[i] for i in inceid]\n",
    "print(incidx)\n",
    "incidx=np.array(incidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../../results/cache/0-1img',matrix0_1[incidx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../../results/cache/coximg',np.array(matrix)[incidx,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
